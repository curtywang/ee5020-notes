{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b15e9-6c4e-43b5-88cf-ecd5a8be02cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a49bcb-082d-46e3-b920-591541bad759",
   "metadata": {},
   "source": [
    "## Revisiting Bayes' Theorem\n",
    "\n",
    "Basic conditional probability: \n",
    "\n",
    "$p(B|A)=\\frac{p(B\\cap A)}{p(A)}$ (1)\n",
    "\n",
    "Since $p(B|A) \\ne p(A|B)$, BUT $p(B \\cap A) = p(A \\cap B)$: \n",
    "\n",
    "$p(A|B)=\\frac{p(B\\cap A)}{p(B)}$ (2)\n",
    "\n",
    "Then, we derive Bayes' rule: \n",
    "\n",
    "$p(A|B)=\\frac{p(B|A)p(A)}{p(B)}$ (3)\n",
    "\n",
    "Now, let's assume that our model parameters are $\\theta$ and dataset is $y$:\n",
    "\n",
    "$p({\\boldsymbol{\\theta }}|{\\boldsymbol{y}})=\\frac{p({\\boldsymbol{y}}|{\\boldsymbol{\\theta }})p({\\boldsymbol{\\theta }})}{p({\\boldsymbol{y}})}$ (4)\n",
    "\n",
    "Often, we just use the proportional distribution, rather than the fully-normalized posterior:\n",
    "\n",
    "$p({\\boldsymbol{\\theta }}|{\\boldsymbol{y}})\\propto p({\\boldsymbol{y}}|{\\boldsymbol{\\theta }})p({\\boldsymbol{\\theta }})$ (5)\n",
    "\n",
    "Now, we can break this down into different terms:\n",
    "\n",
    "- $p(\\theta)$ is known as the **prior**, probability of the model (hypothesis) before seeing data\n",
    "- $p(\\theta | y)$ is known as the **posterior**, probability of the model (hypothesis) after seeing data\n",
    "- $p(y | \\theta)$ is known as the **likelihood**, probability of the data given a hypothesis\n",
    "\n",
    "**_So, what does this mean in terms of solving a statistical problem?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a700844-17d0-40ff-aedf-1f2378d5e459",
   "metadata": {},
   "source": [
    "- **Prior:** use any background information we have, or any assumptions we have\n",
    "- **Likelihood:** use any data we can collect to compute probability for each hypothesis\n",
    "- **Posterior:** A result of a **Bayesian update** (using prior probabilities and new data to compute current probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c49ee2-db04-4615-9ab6-e2ddfdb20eb0",
   "metadata": {},
   "source": [
    "## Bayesian statistics treat models as non-permanent (ever evolving) distributions\n",
    "\n",
    "Benefits:\n",
    "\n",
    "1. Prior information is captured\n",
    "2. Updates can increase accuracy of model\n",
    "3. Models are interpretable\n",
    "4. Non-long-run statistics can be captured\n",
    "\n",
    "Drawbacks:\n",
    "\n",
    "1. Prior assumptions are weighed in\n",
    "2. More complex setup\n",
    "\n",
    "![Bayesian statistics workflow](bayesian_cycle.png)\n",
    "\n",
    "*Figure 1: The Bayesian statistics workflow works similar to humanistic approaches to research problems.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2605b4-82b9-4d7d-ad6f-7ef7725586b7",
   "metadata": {},
   "source": [
    "## Updates via Bayes Tables\n",
    "\n",
    "> Suppose there are two bowls of cookies.\n",
    ">\n",
    "> * Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies. \n",
    ">\n",
    "> * Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.\n",
    ">\n",
    "> Now suppose you choose one of the bowls at random and, without looking, choose a cookie at random. If the cookie is vanilla, what is the probability that it came from Bowl 1?\n",
    "\n",
    "Let's set this up!  Here are the steps:\n",
    "\n",
    "1. What are our variables and how can we relate them?  In other words, what information do we have, and what are we trying to figure out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee02ef1-a84f-4ca1-8974-0c5aa7b8f02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a05f2954-791a-4ae6-8b0e-2b1d9d8ce52e",
   "metadata": {},
   "source": [
    "2. Tabularize our information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263f778-a4bc-47b7-b7d5-420d1051127f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecafd1cc-95cb-48b0-80ed-80c9bc9bf82f",
   "metadata": {},
   "source": [
    "3. Multiply to obtain the un-normalized posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc501d3-1785-4e34-9c16-2c347b01700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68418702-8d01-4653-9e85-e8f065e7912b",
   "metadata": {},
   "source": [
    "4. Normalize the posterior by dividing by the total probability so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70d92f-3483-4e52-9275-324a9bb68782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3339396-31e3-42f5-baa5-6d4d5f28de2e",
   "metadata": {},
   "source": [
    "## The power of Bayesian statistics!\n",
    "\n",
    "### The Monty Hall Problem\n",
    "\n",
    "The Monty Hall problem (one of the most contentious problems in probability!) is based on a game show called *Let's Make a Deal*. If you are a contestant on the show, here's how the game works:\n",
    "1. The host, Monty Hall, shows you three closed doors -- numbered 1, 2, and 3 -- and tells you that there is a prize behind each door.\n",
    "2. One prize is valuable (traditionally a car), the other two are less valuable (traditionally goats).\n",
    "3. The object of the game is to guess which door has the car. If you guess right, you get to keep the car.\n",
    "\n",
    "![Monty hall problem illustrated](monty_hall.png)\n",
    "\n",
    "_Figure 2: The Monty Hall problem illustrated._\n",
    "\n",
    "**The question:** Suppose you pick Door 1. Before opening the door you chose, Monty opens Door 3 and reveals a goat. Then Monty offers you the option to stick with your original choice or switch to the remaining unopened door. _To maximize your chance of winning the car, should you stick with Door 1 or switch to Door 2?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a1afd-4a01-4e7c-b707-95d0c450b642",
   "metadata": {},
   "source": [
    "### Bayes to the rescue! The solution to the Monty Hall problem:\n",
    "\n",
    "To answer this question, we have to make some assumptions about the behavior of the host:\n",
    "\n",
    "1.  Monty always opens a door and offers you the option to switch.\n",
    "\n",
    "2.  He never opens the door you picked or the door with the car.\n",
    "\n",
    "3.  If you choose the door with the car, he chooses one of the other\n",
    "    doors at random.\n",
    "\n",
    "We start with three hypotheses: the car might be behind Door 1, 2, or 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca34759-4eba-4769-b220-9cc6fb3db4fe",
   "metadata": {},
   "source": [
    "According to the statement of the problem, the prior probability for each door is 1/3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c4597-b3a4-4072-a8f4-e86c81fa4ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5405018a-c0f2-43d0-9419-8c59e31616dc",
   "metadata": {},
   "source": [
    "We also have new data, where Monty opened Door 3 and revealed a goat. Let's convert this data into the probability for each hypothesis (likelihood):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e38d3-de7f-4a01-98b9-f1983d2aee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a77b279b-d846-4356-ae2e-ed9ee868dae9",
   "metadata": {},
   "source": [
    "Now, we can perform a Bayesian update (compute the unnormalized posterior and normalized posterior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f177fd9-61e7-49e2-8aff-1890d63c1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90c1f54-a5b2-4e87-a86f-66a4bc04fb4c",
   "metadata": {},
   "source": [
    "**Our conclusion:** So, should we stick with Door 1 or switch to Door 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d917c-fcbd-46ae-b46b-3c898edb9176",
   "metadata": {},
   "source": [
    "## Distribution functions\n",
    "\n",
    "**pmf: Probability mass function (discrete), $f_X(x) = p(X = x)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a0c6c-d780-4b15-97d3-cb0c83d90fdd",
   "metadata": {},
   "source": [
    "**pdf: Probability density function (continuous), $f_X(x) = \\frac{dF_X(x)}{dx}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0ac58-1702-4d76-8480-55d854421c59",
   "metadata": {},
   "source": [
    "**cdf: Cumulative distribution function, $F_X(x) = p(X \\le x)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fe95b-487b-4470-bccd-ffc4501711db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8748a21a-dd92-47d1-b5ba-eb9f1cd2a246",
   "metadata": {},
   "source": [
    "## Bayesian estimation example\n",
    "\n",
    "I often see rabbits in the garden behind my house, but it’s not easy to tell them apart, so I don’t really know how many there are.\n",
    "\n",
    "Suppose I deploy a motion-sensing camera trap that takes a picture of the first rabbit it sees each day. After three days, I compare the pictures and conclude that two of them are the same rabbit and the other is different.\n",
    "\n",
    "How many rabbits visit my garden?\n",
    "\n",
    "To answer this question, we have to think about the prior distribution and the likelihood of the data:\n",
    "\n",
    "- I have sometimes seen four rabbits at the same time, so I know there are at least that many. I would be surprised if there were more than 10. So, at least as a starting place, I think a uniform prior from 4 to 10 is reasonable.\n",
    "\n",
    "- To keep things simple, let’s assume that all rabbits who visit my garden are equally likely to be caught by the camera trap in a given day. Let’s also assume it is guaranteed that the camera trap gets a picture every day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8259f2-e22e-4677-84b1-55a22b948993",
   "metadata": {},
   "source": [
    "1. Setup the prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff888f8-b136-4ae9-8291-4c69cd19038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32c075e5-bb6e-45e9-ac8d-9f933b58617a",
   "metadata": {},
   "source": [
    "2. Incorporate data into a likelihood distribution.  Our data is that two rabbits were the same, and the third is different. This means that the probability for capturing the same rabbit can be found by multiplying two probabilities:\n",
    "    1. That the second image is the same rabbit as the first: $1/N$ (uniform probability), where $N$ is the number of rabbits.\n",
    "    2. That the third image is a different rabbit as the first two images: $\\frac{N-1}{N}$ (uniform probability complement).\n",
    "\n",
    "Normally, our data is from experiments, but in this case we have a model that is \"simulated\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7b3a5-124e-4934-876d-c1a325cacde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ea334a-7871-4450-be9b-6d7ce0c47313",
   "metadata": {},
   "source": [
    "3. Now, perform our Bayesian update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ef05b-ca48-47c6-a22c-c1232adb72f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba41ea-a62d-470f-a1d9-907c3435439e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bafeb159-0630-4158-b5a7-5316d045fe6a",
   "metadata": {},
   "source": [
    "Let's plot our posteriors, and see how many numbers of rabbits are likely based on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b747e-758d-4876-a2f9-f658a7f692eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c77e86a-7a66-44a3-bca0-632f0d3f7af5",
   "metadata": {},
   "source": [
    "Just like with frequentist estimation, we want to know how confident we can be! Enter the Bayesian version of a confidence interval, the 90% **credible interval**, which are the quantities that bound the middle 90% probability, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11255485-80cc-48ec-9934-9cdd7dce3a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe87923-7023-43fc-b056-045232092ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4f0b5-65ab-497f-8aa2-83e00d34fc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03036c40-14db-4cf3-94c3-cb9c47f005ff",
   "metadata": {},
   "source": [
    "**What can we draw from this?**\n",
    "\n",
    "1. Our credible interval is incredibly large.  We probably need more data.\n",
    "2. If we adjust the prior, we will get vastly different posteriors. The prior we have is called an uninformative prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddc9c9-ee19-4ea8-8386-368740c5f114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
