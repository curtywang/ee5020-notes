{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491c8cdd-42db-4034-bc2f-2f554603d9f2",
   "metadata": {},
   "source": [
    "# Black-box Optimization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ddfb9-06d2-47bd-a79d-327eb62bf587",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "You've probably noticed that the SciPy optimization routines, and indeed most optimization routines, assume a continuous parameter.  However, there come cases when you would like to use a discrete parameter, such as $n$ in HW4.\n",
    "\n",
    "There are two different strategies:\n",
    "1. Pick an optimization method that accepts the parameter as an integer constraint\n",
    "2. Round the parameter input within the objective function\n",
    "\n",
    "Either of these strategies work, it is up to you.  Generally strategy 2 is easiest, since you don't need to find a specific algorithm.  Strategy 1 will require an algorithm that supports integer constraints, like `RBFOpt` (these are tricky to install sometimes).\n",
    "\n",
    "## Black-box (derivative-free) optimization libraries\n",
    "\n",
    "<!-- Numerical engineers really like to use Fortran, so make sure to install `flang` (Fortran language compiler) first! -->\n",
    "\n",
    "Some of these packages are broken on Windows in `conda-forge` due to the Fortran compiler required. Numerical engineers tend to use Fortran since it's very close to the applied mathematics. So, you'll have to use `pip` to install rather than `mamba`.\n",
    "\n",
    "Here are the different libraries that provide black-box optimization:\n",
    "- `scipy.optimize` (see the differential_evolution() and dual_annealing() functions)\n",
    "- `PDFO` (Powell's Derivative-Free Optimization)\n",
    "- `nevergrad` (Facebook Research's Never Gradient Optimizers)\n",
    "- `RBFOpt` (IBM Watson's derivative-free optimization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768701a-ad48-4b42-ba7b-d84025974038",
   "metadata": {},
   "source": [
    "## Why do we need a special optimizer for integer or black-box optimization?\n",
    "\n",
    "Short but not technically correct answer: There is no gradient with integers (since integers are not real numbers), so gradient-based methods (most optimization methods) will not work.\n",
    "\n",
    "The true answer is a bit more complicated.  General functions (black-box functions) are usually nonlinear, so linear optimization functions will not work.  In addition, integer constraints make any optimization problem NP-complete (as in, [nondeterministic-polynomial compute time](https://en.wikipedia.org/wiki/NP-completeness)), so the algorithms that solve these problems are usually special in some transformation of the problem.\n",
    "\n",
    "## Example using rounding (strategy 2)\n",
    "\n",
    "We can pretend that we only accept integers for the squaring function, and try to find the minimal x for the square function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a0ce6-00a6-4580-9e84-27232a09f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0116f-bd22-490a-8d85-2d6dbd58f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(a: Union[int, float]) -> Union[int, float]:\n",
    "    return np.square(np.rint(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e7c56-8dfc-4ffb-9088-06630fc3c77c",
   "metadata": {},
   "source": [
    "We know visually that for the base function $f(x) = x^2$ that $x = 0$ would be the minimal in both real and discrete number spaces.  So let's see if we can verify this with differential evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3125486-bf46-4078-9f77-9f4b6024aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.optimize.differential_evolution(square, bounds=[(-20, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed23a09-8024-4cb5-964c-450ad1a0f64e",
   "metadata": {},
   "source": [
    "What are the components of the above output?\n",
    "- `x`: The optimization's final value for the parameter\n",
    "- `nfev`: Number of function evaluations\n",
    "- `nit`: Number of iterations\n",
    "- `fun`: Value of the objective function at the `x` given\n",
    "\n",
    "What do these outputs imply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40651615-c0ec-4d84-aa8d-983b288b4546",
   "metadata": {},
   "source": [
    "Let's do a slightly more complex function, such as a function that isn't so smooth.  Let's define a piecewise black-box function:\n",
    "\n",
    "- If the input $a$ is greater than 3, the output is $a^2 + a$.\n",
    "- If the input $a$ is less than -1, the output is $a^2 + a$.\n",
    "- If the input $-1 \\le a \\le 3$, the output is $a^4 + 10$.\n",
    "\n",
    "One can see why black-box function optimization is useful -- no assumptions are made about the function.\n",
    "\n",
    "Let's begin by plotting the function for $-20 \\le a \\le 20$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1fb97-7fe1-4917-bb49-cc160ec4e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funny_piecewise(a_in: float) -> float:\n",
    "    a = np.rint(a_in)\n",
    "    if a > 3.0:\n",
    "        return np.power(a, 2) - a\n",
    "    elif a < -1.0:\n",
    "        return np.power(a, 2) + a\n",
    "    else:\n",
    "        return np.power(a, 4) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633c144-696e-42a9-a810-098e1c1472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(-20, 20, 40)\n",
    "y_range = [funny_piecewise(x) for x in x_range]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x_range, y_range, label=\"funny piecewise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cda80a-2021-4df1-a95a-fd5a4ebcc883",
   "metadata": {},
   "source": [
    "We see now that the minimal is no longer 0, and is probably closer to -2.  Let's use the `differential_evolution()` function to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb48a6-4ef0-4c13-90f7-a880ab2c7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.optimize.differential_evolution(funny_piecewise, bounds=[(-20, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ded90-57ad-4808-9bf4-a357d1a49fd9",
   "metadata": {},
   "source": [
    "What do we end up getting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d77b8a-7218-479f-a735-877b767a109d",
   "metadata": {},
   "source": [
    "## Example using `PDFO` on strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d01ff6-baee-4d26-86f1-0e8b4bfb0f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe9176-173c-4d55-aba8-d6cc5f1465eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
